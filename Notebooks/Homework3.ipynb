{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as scs\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Q1: Probability of error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a method to calculate the probability that you make at least one error in a set of m hypothesis tests, given the specified alpha threshold, ie. the probability of at least one false positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2709999999999999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# atleastone_error_rate(m,alpha) takes as input m (the number of independent hypothesis \n",
    "# tests conducted), and alpha, the significance threshold and returns the probablilty \n",
    "# of making at least one error in the m tests\n",
    "import scipy.stats as st\n",
    "\n",
    "def atleastone_error_rate(m,alpha):\n",
    "    error_rate = 1-(1-alpha)**m\n",
    "    return(error_rate)\n",
    "\n",
    "# For example,\n",
    "atleastone_error_rate(3,0.10) # -> 0.2709999999999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q1:test1",
     "locked": true,
     "points": "0.33",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q1:test2",
     "locked": true,
     "points": "0.33",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q1:test3",
     "locked": true,
     "points": "0.34",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Q2: A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Consider the AB test results in the csv file 'ab_data_demo.csv'. The data consists of 2000 users. The column 'group' indicates whether the user is assigned to the control group (A) or the treatment group (B). The column 'premium_signed_up' indicates whether the user signed up for the premium service or not with a 1 or 0, respectively. \n",
    "\n",
    "We want to test whether changes made to the signup process (treatment B) for a premium account significantly increased the sign up rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "(a) Write a method to calculate the signup rate for both the control (A) and treatment (B) groups and return as a tuple.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08891108891108891, 0.021021021021021023)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_signup_rate(filename) takes as input a csv file to read the data from, \n",
    "# and returns a tuple with:\n",
    "# the calculated signup rate (1=sign up) for each of the two groups A and B.\n",
    "\n",
    "def get_signup_rate(filename):\n",
    "    \n",
    "    data = pd.read_csv(filename)\n",
    "    groupa_rate = (data[(data['group']=='A') & (data['premium_signed_up']==1)].count()[0])/(data[data['group']=='A'].count()[0])\n",
    "    groupb_rate = (data[(data['group']=='B') & (data['premium_signed_up']==1)].count()[0])/(data[data['group']=='B'].count()[0])\n",
    "    return(groupa_rate, groupb_rate)\n",
    "\n",
    "# For example,\n",
    "get_signup_rate('ab_data_demo.csv') # -> (0.08891108891108891, 0.021021021021021023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q2a",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "(b) Write a method to test the hypothesis that the treatment (B) significantly increased the signup rate compared to the control (A). First, compute the contigency table with rows corresponding to groups A and B, and columns indicating sign-up (1) or not (0). Then, use a chi-square test with the specified alpha, and return the pvalue and associated decision (accept/reject).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.356126765709662e-11, 'reject')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_hypothesis(filename, alpha) takes as input a csv file to read the data from, \n",
    "# and returns a tuple with:\n",
    "# (1) the first element as the p value returned from the chi-square test, and \n",
    "# (2) the second element as a string which returns one of two values: \"accept\" or \"reject\", \n",
    "# indicating whether the hypothesis, using the specified alpha, is accepted or rejected.\n",
    "\n",
    "# For example,\n",
    "# test_hypothesis('ab_data_demo.csv', 0.05) -> (5.356126765709662e-11, 'reject')\n",
    "\n",
    "def test_hypothesis(filename, alpha):\n",
    "    \n",
    "    data = pd.read_csv(filename)\n",
    "    data_group = data.groupby(['group','premium_signed_up']).size()\n",
    "    A0 = data_group.loc[('A',0)]\n",
    "    A1 = data_group.loc[('A',1)]\n",
    "    B0 = data_group.loc[('B',0)]\n",
    "    B1 = data_group.loc[('B',1)]\n",
    "    obs = np.array([[A0, A1],[B0, B1]])\n",
    "    pval = chi2_contingency(obs)[1]\n",
    "    if pval > alpha:\n",
    "        result = 'accept'\n",
    "    else:\n",
    "        result = 'reject'\n",
    "    return(pval, result)\n",
    "\n",
    "test_hypothesis('ab_data_demo.csv', 0.05)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q2b",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Q3: Bonferroni correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Write a method to calculate the adjusted alpha threshold to use when applying a Bonferroni correction to a set of m hypothesis tests, given the specified alpha threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03333333333333333"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bonferroni_alpha(m,alpha) takes as input m (the number of independent hypothesis \n",
    "# tests conducted), and alpha, the significance threshold and returns the adjusted \n",
    "# alpha threshold to use when applying a Bonferroni correction\n",
    "\n",
    "\n",
    "def bonferroni_alpha(m,alpha):\n",
    "    p_val = alpha/m\n",
    "    return(p_val)\n",
    "\n",
    "# For example,\n",
    "bonferroni_alpha(3,0.10) # -> 0.03333333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q3:test1",
     "locked": true,
     "points": "0.5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q3:test2",
     "locked": true,
     "points": "0.5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Q4: False Discovery Rate (FDR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "(a) Write a method to calculate the False Discovery Rate (FDR) from a given vector of p-values and specified alpha threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35714285714285715"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate_FDR(p_values, alpha) takes as input a vector of p vaiues and specified \n",
    "# alpha, and returns the False Discovery Rate (FDR) as a floating point number. \n",
    "\n",
    "def calculate_FDR(p_values, alpha):\n",
    "    \n",
    "    count = 0\n",
    "    for n in p_values:\n",
    "        if n< alpha:\n",
    "            count += 1\n",
    "    FDR = len(p_values)*alpha/count\n",
    "    return(FDR)\n",
    "    \n",
    "# For example,\n",
    "p_values = [0.001, 0.008, 0.039, 0.041, 0.042, 0.06, 0.074, 0.205, 0.212, 0.216, 0.222, 0.251, 0.269, 0.275, 0.34,\n",
    "           0.341, 0.384, 0.569, 0.594, 0.696, 0.762, 0.94, 0.942, 0.975, 0.986]\n",
    "calculate_FDR(p_values, 0.10) # -> 0.35714285714285715\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q4a:test1",
     "locked": true,
     "points": "0.5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q4a:test2",
     "locked": true,
     "points": "0.5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Write a method to calculate the adjusted alpha threshold to use to achieve the specified False Discovery Rate (FDR) with a given vector of p-values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate_alpha_for_FDR(p_values, fdr) takes as input a vector of p vaiues and specified \n",
    "# False Discovery Rate, and returns the adjusted alpha that will achieve the target FDR. \n",
    "\n",
    "def calculate_alpha_for_FDR(p_values, fdr):\n",
    "    targetFDR = fdr\n",
    "    p_values.sort(reverse=True)\n",
    "    numP = len(p_values)\n",
    "    l = []\n",
    "    targetIdx = -1\n",
    "    for i in range(numP):\n",
    "        numSig = numP - (i)\n",
    "        currAlpha = p_values[i]\n",
    "        f = (numP * currAlpha) / numSig\n",
    "        l.append(f)\n",
    "        if f <= targetFDR and targetIdx < 0:\n",
    "            targetIdx = i\n",
    "    return(p_values[targetIdx])\n",
    "    \n",
    "    \n",
    "# For example,\n",
    "p_values = [0.001, 0.008, 0.039, 0.041, 0.042, 0.06, 0.074, 0.205, 0.212, 0.216, 0.222, 0.251, 0.269, 0.275, 0.34,\n",
    "           0.341, 0.384, 0.569, 0.594, 0.696, 0.762, 0.94, 0.942, 0.975, 0.986]\n",
    "calculate_alpha_for_FDR(p_values, 0.25) # -> 0.06\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q4b:test1",
     "locked": true,
     "points": "0.5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q4b:test2",
     "locked": true,
     "points": "0.5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Q5: Multiple hypothesis tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Consider the file 'doc_term_demo.csv'. Each column corresponds to a word and each row corresponds to a portition of the Wikepedia document describing a university. There is a header row specifying the words, and the first column records the document name. The value in the cell (i,j) specifies the number of times word j is used in document i. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Write a method to read in the data and test the hypothesis that the counts for a specified pair of words differs significantly different across a specified pair of schools. \n",
    "\n",
    "For example, for the pair of schools 'purdue.txt','cornell.txt' and the pair of words 'research' and 'university', construct a contingency table with rows corresponding to the schools and columns corresponding to the words, with the cells recording the words counts in each school documnent. Then use a chi-square test to assess whether there's a signifcant difference in the observed counts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4970314541039976, 'accept')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# doc_term_hypothesis(filename, word1, word2, school1, school2, alpha) takes as input \n",
    "# a csv file to read the data from, and returns a tuple with:\n",
    "# (1) the first element as the p value returned from the chi-square test, \n",
    "# comparing the word coutns for the two schools, and \n",
    "# (2) the second element as a string which returns one of two values: \"accept\" or \"reject\", \n",
    "# indicating whether the hypothesis, using the specified alpha, is accepted or rejected.\n",
    "\n",
    "\n",
    "filename = 'doc_term_demo.csv'\n",
    "\n",
    "def doc_term_hypothesis(filename,word1,word2,school1,school2,alpha):\n",
    "    \n",
    "    data = pd.read_csv(filename, index_col=0)\n",
    "    cor_uni = data.loc[school1,word1]\n",
    "    cor_research = data.loc[school1,word2]\n",
    "    pur_uni = data.loc[school2,word1]\n",
    "    pur_research = data.loc[school2,word2]\n",
    "    obs = np.array([[cor_uni, cor_research],[pur_uni, pur_research]])\n",
    "    pval = chi2_contingency(obs)[1]\n",
    "    if pval > alpha:\n",
    "        result = 'accept'\n",
    "    else:\n",
    "        result = 'reject'\n",
    "    return(pval, result)\n",
    "\n",
    "# For example,\n",
    "doc_term_hypothesis('doc_term_demo.csv','university','research','purdue.txt','cornell.txt',0.1)\n",
    "# -> (0.4970314541039976, 'accept')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q5a:test1",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q5a:test2",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "(b) Write a method to read in the data and test multiple hypothesese for a specified pair of schools. Consider all possible pairs of words, and test the hypothesis that the words counts differ significantly across the two schools, using the specified alpha threshold.\n",
    "\n",
    "Note: only conduct tests on words that have non-zero values for both schools. I.e., every row and column in the contingency table should sum to >0.\n",
    "\n",
    "Return a tuple with (i) the total number of tests conducted, and (ii) the number of significant tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 41)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# school_term_hypotheses(filename, school1, school2, alpha) takes as input \n",
    "# a csv file to read the data from, and returns a tuple with:\n",
    "# (1) the total number of chi-square tests conducted when comparing all word pairs \n",
    "# for the two schools, and \n",
    "# (2) the number of tests that were significant, using the specified alpha.\n",
    "\n",
    "filename = 'doc_term_demo.csv'\n",
    "\n",
    "def school_term_hypotheses(filename,school1,school2,alpha):\n",
    "    \n",
    "    data = pd.read_csv(filename, index_col=0)\n",
    "    school = data.loc[[school1,school2],:]\n",
    "    school_drop_zero = school.replace(0,np.nan).dropna(axis=1,how=\"all\")\n",
    "    data_clean = school_drop_zero.replace(np.nan,0)\n",
    "    significant = 0\n",
    "    trial = 0\n",
    "    for i in range(len(data_clean.columns)):\n",
    "        for j in range(i + 1, len(data_clean.columns)):\n",
    "            selected_df = data_clean.iloc[:,[i,j]]\n",
    "            if selected_df.iloc[0, 0] + selected_df.iloc[0, 1] == 0 or selected_df.iloc[1, 0] + selected_df.iloc[1, 1] == 0:\n",
    "                continue\n",
    "            pval = chi2_contingency(selected_df)[1]\n",
    "            trial += 1\n",
    "            if pval < alpha:\n",
    "                significant += 1\n",
    "    return(trial, significant)\n",
    "\n",
    "        \n",
    "# For example,\n",
    "school_term_hypotheses('doc_term_demo.csv','purdue.txt','uiuc.txt',0.05)\n",
    "# -> (62, 41)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q5b:test1",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q5b:test2",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Repeat Q5b, but use a Bonferroni correction when assessing significance.\n",
    "\n",
    "Return a tuple with (i) the adjusted alpha threshold after applying the Bonferroni correction, and (ii) the number of significant tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0008064516129032258, 23)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# school_term_hypotheses_BC(filename, school1, school2, alpha) takes as input \n",
    "# a csv file to read the data from, and returns a tuple with:\n",
    "# (1) the adjusted alpha threshold after applying the Bonferroni correction, and \n",
    "# (2) the number of tests that were significant, using the specified alpha and \n",
    "# a Bonferonni correction.\n",
    "\n",
    "filename = 'doc_term_demo.csv'\n",
    "\n",
    "def school_term_hypotheses_BC(filename,school1,school2,alpha):\n",
    "    \n",
    "    \n",
    "    data = pd.read_csv(filename, index_col=0)\n",
    "    school = data.loc[[school1,school2],:]\n",
    "    school_drop_zero = school.replace(0,np.nan).dropna(axis=1,how=\"all\")\n",
    "    data_clean = school_drop_zero.replace(np.nan,0)\n",
    "    significant = 0\n",
    "    trial = 0\n",
    "    pvalues = []\n",
    "    for i in range(len(data_clean.columns)):\n",
    "        for j in range(i + 1, len(data_clean.columns)):\n",
    "            selected_df = data_clean.iloc[:,[i,j]]\n",
    "            if selected_df.iloc[0, 0] + selected_df.iloc[0, 1] == 0 or selected_df.iloc[1, 0] + selected_df.iloc[1, 1] == 0:\n",
    "                continue\n",
    "            pval = chi2_contingency(selected_df)[1]\n",
    "            trial += 1\n",
    "            pvalues.append(pval)\n",
    "            if pval < alpha:\n",
    "                significant += 1\n",
    "    Bonferroni = alpha/trial\n",
    "    new_significant = 0\n",
    "    for val in pvalues:\n",
    "        if val < Bonferroni:\n",
    "            new_significant += 1\n",
    "        \n",
    "    return(Bonferroni, new_significant)\n",
    "\n",
    "\n",
    "# For example,\n",
    "school_term_hypotheses_BC('doc_term_demo.csv','purdue.txt','uiuc.txt',0.05)\n",
    "# -> (0.0008064516129032258, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q5c:test1",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q5c:test2",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Repeat Q5b to test multiple hypotheses, but take as input a specified FDR rate and return the corresponding adjusted alpha threshold.\n",
    "\n",
    "Return a tuple with (i) the adjusted alpha threshold for the target FDR rate, and (ii) the number of significant tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.011798507503906602, 39)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# school_term_hypotheses_FDR(filename, school1, school2, targetFDR) takes as input \n",
    "# a csv file to read the data from, and returns a tuple with:\n",
    "# (1) the adjusted alpha threshold to meet the target FDR rate, and \n",
    "# (2) the number of tests that were significant, using the FDR correction.\n",
    "\n",
    "filename = 'doc_term_demo.csv'\n",
    "\n",
    "def school_term_hypotheses_FDR(filename,school1,school2,targetFDR):\n",
    "    \n",
    "    data = pd.read_csv(filename, index_col=0)\n",
    "    school = data.loc[[school1,school2],:]\n",
    "    school_drop_zero = school.replace(0,np.nan).dropna(axis=1,how=\"all\")\n",
    "    data_clean = school_drop_zero.replace(np.nan,0)\n",
    "    significant = 0\n",
    "    trial = 0\n",
    "    pvalues = []\n",
    "    for i in range(len(data_clean.columns)):\n",
    "        for j in range(i + 1, len(data_clean.columns)):\n",
    "            selected_df = data_clean.iloc[:,[i,j]]\n",
    "            if selected_df.iloc[0, 0] + selected_df.iloc[0, 1] == 0 or selected_df.iloc[1, 0] + selected_df.iloc[1, 1] == 0:\n",
    "                continue\n",
    "            pval = chi2_contingency(selected_df)[1]\n",
    "            trial += 1\n",
    "            pvalues.append(pval)\n",
    "#             if pval < alpha:\n",
    "#                 significant += 1\n",
    "                \n",
    "    targetFDR = targetFDR            \n",
    "    pvalues.sort(reverse=True)\n",
    "    numP = len(pvalues)\n",
    "    l = []\n",
    "    targetIdx = -1\n",
    "    for i in range(numP):\n",
    "        numSig = numP - (i)\n",
    "        currAlpha = pvalues[i]\n",
    "        f = (numP * currAlpha) / numSig\n",
    "        l.append(f)\n",
    "        if f <= targetFDR and targetIdx < 0:\n",
    "            targetIdx = i\n",
    "#     print(pvalues[targetIdx]) #adjusted alpha\n",
    "    adj_alpha=pvalues[targetIdx]\n",
    "    \n",
    "    c=0\n",
    "    for i in range(len(pvalues)):\n",
    "        if pvalues[i]<adj_alpha:\n",
    "            c=c+1\n",
    "        \n",
    "    return(adj_alpha, c)\n",
    "\n",
    "# For example,\n",
    "school_term_hypotheses_FDR('doc_term_demo.csv','purdue.txt','uiuc.txt',0.1)\n",
    "# -> (0.011798507503906602, 39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q5d:test1",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q5d:test2",
     "locked": true,
     "points": "1",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
